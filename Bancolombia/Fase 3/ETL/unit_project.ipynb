{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff1e751",
   "metadata": {},
   "source": [
    "## Proyecto Integrador\n",
    "Datos de entrada:\n",
    "* `sales.csv`.\n",
    "  ```csv\n",
    "   id,nombre,fecha,venta\n",
    "   1,juan,2024-01-10,100\n",
    "   2,Ana,2024-01-11,200\n",
    "   3,pedro,2024/01/12,NaN\n",
    "   4,JUAN,2024-01-13,150\n",
    "\n",
    "  ```\n",
    "* `clients.xlsx`.\n",
    "  | id  | nombre\\_cliente | ciudad   | correo                                      |\n",
    "  | --- | --------------- | -------- | ------------------------------------------- |\n",
    "  | 1   | Maria           | Medellín | maria\\_gmail.com                            |\n",
    "  | 2   | Andres          | Bogotá   | [andres@gmail.com](mailto:andres@gmail.com) |\n",
    "  | 3   | carlos          | Cali     | [carlos@yahoo.com](mailto:carlos@yahoo.com) |\n",
    "\n",
    "1. Cada minuto se ejecuta el ETL.\n",
    "2. Extrae datos de **CSV (ventas) y Excel (clientes)**.\n",
    "3. Transforma los datos:\n",
    "   * Normalize nombres.\n",
    "   * Corrige fechas y NaN en ventas.\n",
    "   * Valida correos en clientes.\n",
    "4. Carga los datos limpios en PostgreSQL en las tablas:\n",
    "   * `ventas`\n",
    "   * `clientes`\n",
    "5. Ejecuta el request:\n",
    "   ```sql\n",
    "   SELECT * FROM ventas;\n",
    "   sELECT * FROM clientes;\n",
    "   ```\n",
    "   Se deben ver los datos limpios y normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309efaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "import schedule\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1340608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data\n",
    "sales_data = {\n",
    "    'id':[1,2,3,4,],\n",
    "    'name':['juan','Ana','pedro','JUAN'],\n",
    "    'date':['2024-01-10','2024-01-11','2024/01/12','2024-01-13'],\n",
    "    'sale':[100,200,None,150]\n",
    "}\n",
    "clients_data = {\n",
    "    'id':[1,2,3],\n",
    "    'client_name':['Maria','Andres','carlos'],\n",
    "    'city':['Medellín','Bogotá','Cali'],\n",
    "    'email':['maria%_gmail.com','andres@gmail.com','carlos@yahoo.com']\n",
    "}\n",
    "\n",
    "sales_df = pd.DataFrame(sales_data)\n",
    "clients_df = pd.DataFrame(clients_data)\n",
    "\n",
    "sales_df.to_csv('sales.csv',index=False)\n",
    "clients_df.to_excel('clients.xlsx',sheet_name='clients_data',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3c0152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check email function\n",
    "def is_valid_email_regex(email):\n",
    "    if pd.isna(email) or not isinstance(email, str):\n",
    "        return False\n",
    "    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "    return bool(re.match(pattern, email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "019b791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conection data\n",
    "user = 'postgres'\n",
    "password = 'root'\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "database = 'postgres'\n",
    "# Create engine conection\n",
    "engine = create_engine(f\"postgresql://{user}:{password}@{host}:{port}/{database}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92001338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL\n",
    "def etl_job():\n",
    "    print(f'running: {datetime.now().strftime('%H-%M-%S')}')\n",
    "    # Extract\n",
    "    salesdf = pd.read_csv('sales.csv')\n",
    "    clientsdf = pd.read_excel('clients.xlsx',sheet_name='clients_data')\n",
    "    \n",
    "    # Transform\n",
    "    # Sales\n",
    "    salesdf['name'] = salesdf['name'].str.title()\n",
    "    salesdf['date'] = pd.to_datetime(salesdf['date'],errors='coerce')\n",
    "    salesdf['sale'] = salesdf['sale'].fillna(salesdf[salesdf['sale']>0]['sale'].mean())\n",
    "    # Clients\n",
    "    clientsdf['client_name'] = clientsdf['client_name'].str.title()\n",
    "    clientsdf['city'] = clientsdf['city'].fillna('Without city')\n",
    "    clientsdf['email'] = np.where(clientsdf['email'].apply(is_valid_email_regex),clientsdf['email'],'invalid_email')\n",
    "    \n",
    "    # Load\n",
    "    # Sales\n",
    "    salesdf.to_sql('sales',engine,if_exists='replace',index=False)\n",
    "    clientsdf.to_sql('clients',engine,if_exists='replace',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475b5f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: 11-39-40\n",
      "   id client_name      city             email\n",
      "0   1       Maria  Medellín     invalid_email\n",
      "1   2      Andres    Bogotá  andres@gmail.com\n",
      "2   3      Carlos      Cali  carlos@yahoo.com\n",
      "\n",
      "   id   name       date   sale\n",
      "0   1   Juan 2024-01-10  100.0\n",
      "1   2    Ana 2024-01-11  200.0\n",
      "2   3  Pedro        NaT  150.0\n",
      "3   4   Juan 2024-01-13  150.0\n"
     ]
    }
   ],
   "source": [
    "etl_job()\n",
    "query_clients = 'SELECT * FROM clients'\n",
    "query_sales = 'SELECT * FROM sales'\n",
    "\n",
    "sql_clients = pd.read_sql(query_clients,engine)\n",
    "sql_sales = pd.read_sql(query_sales,engine)\n",
    "\n",
    "print(sql_clients)\n",
    "print()\n",
    "print(sql_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d4915a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: 11-40-40\n",
      "running: 11-41-40\n",
      "running: 11-42-40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m      4\u001b[39m     schedule.run_pending()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     time.sleep(\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Schedule\n",
    "schedule.every(1).minutes.do(etl_job)\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
